主题：代码片段 VS Code 插件的 S3 云同步机制设计

目标：为我们的代码片段管理插件构建一个健壮、可靠且能处理多端冲突的云同步功能，使用 AWS S3 作为存储服务。

一、核心设计原则

1.状态一致性：确保同步后，本地与云端的数据状态保持一致。
2.数据可追溯性：通过详细的历史记录，追踪每一次变更。
3.冲突可检测与解决：机制必须能够识别多端操作可能引发的冲突，并提供合理的解决策略。
4.操作幂等性：重复执行同一同步操作应产生相同的结果，避免副作用。
5.用户友好：同步过程对用户应尽可能透明，关键操作（如冲突解决）需用户确认。

二、云端存储结构 (S3 Bucket 内)

1.代码片段文件：
    * 格式：每个代码片段存储为一个独立的 JSON 文件 (或其他定义格式)。
    * 路径：在 S3 Bucket 内，路径结构将模拟本地的目录结构。例如：`[S3_BUCKET_ROOT]/snippets/vue/my-vue-snippet.json`。
    * 约束：单层目录结构，即 `snippets/` 下的目录不能再包含子目录。

2.历史记录文件 (`history.txt`)：
    * 用途：详细记录每一次对代码库结构或内容的变更操作，是状态重建和冲突分析的核心。
    * 位置：`[S3_BUCKET_ROOT]/history.txt`
    * 格式：每行一条记录，字段以 `|` 分隔：
        `OperationType | FullPath | SHA256Hash | Timestamp`
        *   `OperationType`: `+` (新增), `~` (修改), `-` (删除)。
        *   `FullPath`: 代码片段或目录的完整相对路径 (e.g., `/vue/`, `/vue/basic.vue`)。目录以 `/` 结尾。
        *   `SHA256Hash`:
            *   对于文件操作 (`+`, `~`): 文件内容的 SHA256 哈希值。
            *   对于目录操作 (`+`, `-`) 及文件删除 (`-`): 使用 `#` 作为占位符。
        *   `Timestamp`: 操作发生时的 UTC 时间戳 (ISO 8601 格式，建议精确到毫秒：`YYYY-MM-DDTHH:mm:ss.sssZ`)。
    * 规则：
        1.  文件第一条记录必须是新增 (`+`)。
        2.  新增目录时，先记录目录新增，再记录其下文件新增。
        3.  删除目录时，先记录其下文件删除，再记录目录删除。
        4.  所有记录按时间戳严格递增。

3.元数据文件 (`metadata.json`)：
    * 用途：作为云端当前状态的快照和“索引”，用于快速判断云端是否有更新，并辅助校验。
    * 位置：`[S3_BUCKET_ROOT]/metadata.json`
    * 内容：
        *   `version`: 元数据文件格式的版本号。
        *   `lastSyncTimestamp`: 最后一次成功同步到云端的时间戳 (UTC, ISO 8601)。
        *   `historyFileHash`: 云端 `history.txt` 文件内容的 SHA256 哈希值。用于快速判断 `history.txt` 是否被其他客户端修改。
        *   `files`: 对象，键为代码片段的相对路径，值为 `{ "hash": "sha256_content_hash" }`。
        *   `directories`: 对象，键为目录的相对路径，值为一个简单对象 (e.g., `{}`) 或包含创建时间等信息。

三、核心同步流程

同步操作通常在用户触发或插件预设的自动同步时机执行。

阶段 1: 本地变更检测

1.加载本地上次同步状态:读取本地存储的 `history.txt` 副本（或其派生的状态）。若首次同步，则本地状态为空。
2.重建上次同步的本地快照:根据本地 `history.txt` 副本，在内存中构建出上次同步完成时本地应有的文件/目录结构及哈希。
3.扫描当前本地工作区:获取当前实际的代码片段文件、目录结构及其内容的 SHA256 哈希。
4.比较生成变更集:对比“当前本地实际状态”与“上次同步快照”，识别出：
    *   新增的文件/目录
    *   修改的文件 (内容哈希变化)
    *   删除的文件/目录
5.生成待推送的历史记录 (`pending_local_history_entries`):根据上述变更，按照 `history.txt` 的格式和规则，生成新的历史记录条目。这些条目的时间戳应为变更的实际发生时间或当前同步准备时间。

阶段 2: 拉取与分析远端状态

1.下载核心文件:从 S3 下载最新的 `history.txt` (记为 `remote_history.txt`) 和 `metadata.json` (记为 `remote_metadata.json`)。
2.快速检查远端更新:对比本地缓存的 `metadata.json` 中的 `historyFileHash` 与刚下载的 `remote_metadata.json` 中的 `historyFileHash`。
    *   若哈希不同，或 `remote_metadata.json.lastSyncTimestamp` 晚于本地记录，则表示在本地客户端上次同步后，云端发生了变更。

阶段 3: 冲突检测与处理

* 此阶段仅在检测到远端有变更时执行。

1.识别远端新增变更:从 `remote_history.txt` 中，找出那些在本地上次同步之后发生的记录 (记为 `remote_new_entries`)。
2.比较本地与远端变更:
    * 无冲突:本地变更和远端变更操作了不同的文件/目录。
    * 潜在冲突:
        * 内容冲突:同一文件在本地和远端都被修改。
        * 修改/删除冲突:一端修改了文件，另一端删除了该文件。
        * 路径类型冲突:同一路径，一端创建为文件，另一端创建为目录。
        *   其他更复杂的时序依赖冲突。
3.冲突解决策略:
    * 用户选择 (推荐):提示用户冲突详情，让用户选择保留哪个版本（本地/云端），或都保留（自动重命名）。
    * 最后写入者获胜 (LWW):根据历史记录条目的时间戳，最新的操作生效。
    * 预设策略 (本地优先/云端优先):用户可配置。
    * 创建副本:冲突时，自动将本地版本重命名并拉取云端版本。
    *   解决冲突后，可能需要调整 `pending_local_history_entries`。

阶段 4: 合并变更与推送到 S3

1.合并历史记录:将解决冲突后确认保留的 `pending_local_history_entries` 与被接受的 `remote_new_entries`（如果有），按时间戳和操作依赖关系正确排序，形成最终要追加到 `remote_history.txt` 的 `final_delta_history_entries`。
2.执行 S3 文件操作:
    *   遍历 `final_delta_history_entries`：
        *   `+` (新增文件): 上传对应代码片段文件到 S3。
        *   `~` (修改文件): 上传修改后的代码片段文件到 S3 (覆盖)。
        *   `-` (删除文件): 从 S3 删除对应代码片段文件。
3.上传更新后的历史记录:将 `final_delta_history_entries` 追加到从 S3 下载的 `remote_history.txt` 之后，形成 `new_remote_history.txt`，然后将其上传覆盖 S3 上的 `history.txt`。
4.生成并上传新的元数据:
    *   基于 `new_remote_history.txt` 的最终状态，重新计算云端所有文件的哈希和路径，生成全新的 `new_remote_metadata.json`。
    *   更新其 `lastSyncTimestamp` 为当前时间，`historyFileHash` 为 `new_remote_history.txt` 的哈希。
    *   上传 `new_remote_metadata.json` 到 S3，覆盖旧的元数据文件。
    * 关键：`metadata.json` 应在所有代码片段文件和 `history.txt` 上传成功后再上传，作为本次同步操作“提交”的标志。

阶段 5: 更新本地同步状态

1.  同步成功后，将 S3 上最新的 `history.txt` 和 `metadata.json` 保存到本地的插件存储区，作为下一次同步的基准。

四、关键场景的同步流程

1.首次同步 - 本地有数据，云端为空:
    *   本地生成完整的初始 `history.txt` 和 `metadata.json`。
    *   上传所有代码片段文件、`history.txt`、`metadata.json` 到 S3。
    *   本地保存副本。

2.首次同步 - 本地为空，云端有数据 (例如新设备配置):
    *   提示用户从云端下载。
    *   下载 `metadata.json` 和 `history.txt`。
    *   根据 `history.txt` 重建云端文件结构，并逐一下载所有代码片段文件到本地。
    *   本地保存 `history.txt` 和 `metadata.json` 副本。

3.后续同步:
    * 无本地也无远端变更:快速检查后结束。
    * 仅本地有变更:执行阶段1、2（快速检查）、4、5。
    * 仅远端有变更:执行阶段2，然后将 `remote_new_entries` 应用到本地（下载/删除/修改本地文件），最后执行阶段5。
    * 本地和远端均有变更:执行完整的阶段1到5，包含冲突检测与处理。

五、重要技术考量

1.错误处理与重试:对 S3 的所有 API调用 (上传、下载、删除) 需包含健壮的错误处理和网络重试机制 (如指数退避)。
2.操作原子性模拟:由于 S3 本身不保证跨多个对象的原子操作，我们将 `metadata.json` 的成功上传视为整个同步操作的“提交点”。若此步失败，下次同步会重新评估。
3.并发控制 (可选进阶):若多个设备同时同步的概率极高，可考虑引入基于S3的简单锁机制 (例如，同步开始前创建 `sync.lock` 文件，结束后删除)。但 `historyFileHash` 和时间戳已能处理绝大部分冲突。
4.AWS SDK 使用:
    * 凭证管理:安全存储 AWS Access Key 和 Secret Key (使用 VS Code Secret Storage API)。
    * 异步操作:充分利用 `async/await` 处理 SDK 的 Promise-based API。
5.用户体验 (UX):
    *   清晰的同步状态指示 (状态栏、通知)。
    *   冲突发生时，提供明确的解释和操作选项。
    *   提供手动触发同步的命令。
    *   为调试目的，提供插件内部日志。

六、开发建议

1.模块化实现:将本地文件操作、S3 交互、历史记录生成/解析、冲突检测等逻辑封装成独立模块。
2.迭代开发:
    *   先实现核心文件结构和本地变更检测。
    *   然后实现到 S3 的单向推送和拉取。
    *   接着处理简单合并（无冲突）。
    *   最后完善复杂的冲突检测与用户交互解决机制。
3.充分测试:覆盖各种正常和异常场景，特别是多设备并发操作和冲突场景。
